Finding the digits of the number there 
are two good ways of doing it we can use the division method.

int countDigit(long n)
{
    int count=0;
    while(n>=0)
    {
        n=n/10;
        ++count;
    }
    return count;
}
Recursive Solution
int countDigits(long n)
{
    if(n==0)
        return 0;
    return 1+countDigits(n/10);
}
Logarathmic Solution
int countDigits(long n)
{
    return floor(log10(n)+1);
}
The complexity in case of the Logarathmic solution is O(1).

There the basic of the mathematics will be used as per our need.

For finding out whether a particular number which is being provided to us is palindrome or not we can use the concept of 
finding the reversal of the number if that reversed number is equal to the actual number then we can say that the number is palindrome
while in the second case the number is not palindrome.

For finding the GCD of a particular number we use the naive solution for that particular. We consider all the number which are smaller then the current number 
if any of the smaller numbers divide the number then we increase the count.
The first recursive call basically swaps the two numbers from one location to another.

LCM of two numbers
I/P: a=4,b=6
OP: 12
This will be finding the least number which will be divisible by both the numbers.
1 is a number which is neither prime and nor composite.

Check whether the number is prime or not. 
if(n==2||n==3) return true;
The number is definitely not prime.
Otherwise we can directly check.
if(n%2==0)
    return 

We can create an algorithm that can help us in fetching the prime numbers.
We can find the factors
The current method we will write most of the base cases that we have if n==1
we return a false value;
n==2 || n==3 return true
n%2==0||n%3 ==0
return false;
Here we are directly omiting all the values which are even and there are many numbers which are the factor of there
Now implement our own solution in which we run a loop O(root(n)) times and incrementation is done i=i+6;
if(n%i==0||n%(i+2)==0)
 returnn false;

We will consider all the prime factors which are within a range.
The naive solution that comes to the mind for finding the divisors of the particular number is 
firstly consider all the numbers 
from i=2 i*i<=n;i++{

}
if(isPrime(i))
{
    int x=i;
    while(n%x==0)
    {
        print x;
        x=x*i;
    }
}
(Will print all the prime factors which are possible.)
The better solution to this particular approach would be finding the first prime factor and t
This solution does not require any extra space. The complexity is root(n)

Seive of erasthanoes is the way for finding whether the number are prime or not.
This algorithm only keeps the number which are actually prime as true while all the other values are marked as false.
(Initially all the indices have the values as true)-> after the algorithm does its work. only elements that have 
We mark the multiples of 2,3,5
We are considering only the prime factors of the current number.

To find the power in the solution we need an elegant way. Uses the power of recursion
if the number is 0 then nothing much to be done.

Bitwise operations are performed on the individual bits itself.
Bitwise AND does the bitwise AND of the two numbers while the Bitwise OR does the bitwise OR of the two numbers.
Bitwise arithmetics are very easy to be performed.
left shift takes the number and the number of bits that are to be shifted 
It basically performs the bitwise shifts.

Counting the number of set bits is very easy.
I/P n=5
then 101
right shift and perform AND operation.

Count Set bit algorithm can be in this particular algorithm we create the lookup table and then value is fetch using it.
We divide the number into the chucks of 8 numbers.

void initialize(){
    table[0]=0;
    for(int i=1;i<256;i++)
        table[i] = (i&1)+table[i/2]
}

int count(int n)
{
    int res = table[n&0xff]
    n=n>>8;
    res = res+table[n&0xff];
    n=n>>8;
    res=res+table[n&0xff];
    n=n>>8;
    res=res+table[n&0xff];
}
The lookup table is created in an elegant way.
initial 8 bits and is performed the entry is considered. Then shifting is performed.
Same process is followed for the next 8 bits and then other two batches of 8 bits.'

Recursive program we will mainly focus on in are the direct recursive programs.
Each recursive program needs to have a base case so that it can terminate.

Recursion is used a lot in many fields of computer science. Both recursive and iterative solutions are 
equivalent in power.
Writing recursive code is easy.
There are many recursive problem.


Depth First search has a recursive solution. 
Tail recursion is the one which is executed faster. In case of the tail recursion the recursive call is at 
the bottom.
While in the other recursion the recursion is not tail recursive.

If there is a tail recursion then the changes are easily made by the tail recursive function. They need to do the recursion there is no auxiliary space required in case of the compiler.

We cannot always simply convert the non tail recursive function to a tail recursive function. The best example for this is merge sort 
There is no non tail recursive function for the merge sort merges after calling the function on the two parts 
Thats why quick sort is preferred over the merge sort as quick sort does not have this particular overhead.

Inorder and Preorder traversal should be preferred rather than the Postorder traversal as the post order traversal goes through the tail recursion.

We need to find the base case for a particular probelm the base case is the one which cannot be split further.
The time complexity of the finding palindrome using a recursive solution is O(n) and the space complexity is O(n)

The generating substrings question can be easily solved using the concept of recursion we can consider to include a particular solution or not.

Tower of Hanoi problem is a very basic problem in case of the computer science which uses an elegant recursive solution for solving the particular problem.

In case of the josepheus problem the 
If there is only one person then that particular person is the only person which will be alive at last.
now the problem has been reduced
(jos(n-1,k)+k)%n This will be solving the problem.

In case of the towerofhanoi problem.
if(N==1)
{
    If there is only one disc present then simply move that particular disk from top to some other location.
    cout<<"move disk 1 from rod"<<"to rod"<<to<<endl;
    return 1;
}

int step1=toh(N-1,from,aux,to);
cout<<"move disk "<<N<<" from rod "<<from<<" to rod"<<to<<endl;
step2=toh(N-1,aux,from,to);

In case of the josephus problem we create the solution to the problem that we currently have.
find the possible series in case of the josephus problem.

In the present josepheus circle problem the counting here in this particular case starts form 1. The first person that is present is numbered as 1.
Create a circle and make the equations according to it.

Initially for the concept of the strings. Only english characters were allowed but due to the existence of UTF-16 we can support the characters from multiple languages as per our requirement.

The problems which are associated with the array data structure is that size of the array data structure needs to be predefined.
Insertion to the middle position in case of the array is costly. As we even have to move the elements by one place when we insert a particular value.


In case of the linked list there is no pre allocation of the nodes. We can dynamically create as many nodes as we want.
There is always a head node in case of the linked list that contains the address of the first element.

Insertion to the starting location takes the constant amount of time.

The stacks which are being used in the code walkthrough. we simply consider it as the books one above the other.
LIFO is the strategy which it follows. Pop also happens form the same location only.

There are two corner conditions which happens on the stack. These are mainly overflow and the underflow. Overflow happens when there is no space to insert the elements in the stack while the underflow occurs when we cannot delete the items form the stack.

Stack can be either implemented using the array or the linkedlist.
Applications of the stack:
1) In case of the function calling in the programming language stack is used.
2) Checking for balanced parenthesis.
3) Reversing items.
4) Infix to postfix.
5) Evaluation of prefix and postfix.
6) Stock span problem (V V V important)

There are three notations which are commonly used in case of the stack evaluation. These notations are as follows.
Infix-> the operator in this particular case is present in between. x+y
Postfix-> operator is last  xy+
Prefix-> operator is first. +xy

first of all the precendence is checked for the operators in case of the evaluation of the infix expression. if same precedence then we check for the associativity.

In case of the infix notations we require the precedence and the associativity rules.
In case of the infix expression we require the precedence and the associativity of the operators while in case of the postfix and the prefix expressions we don't require those.

Here the time complexity of the maximum element in k size window is O(n).

The tree data structure is used in when we want to show the heirarchy.

Tree is a non linear data structure which stores the information in a particular order.

Nodes which are just below the current node are called the children of the current node.

There are many trees which are below the current tree. These trees are called the subtree of the current tree.

Application of tree data structures:
1) USED FOR REPRESENTATION OF THE HEIRARCHICAL DATAS.
-> ORGANIZATIONAL INFORMATION CAN BE REPRESENTED USING THE TREE DATA STRUCTURE.
-> FOLDER STRUCTURE.
-> XML/HTML content.
-> In OOP (Inheritence.)
2) Binary Search tree.
3) Binary Heaps.
4) B and B+ trees.
5) in networking.
6) Parse tree.
tries suffix trees binary index tree, segment trees.

binary trees are used a lot therefore we sturt trees. Uninitialized members of the class are always null in java.

In case of the binary search tree implementation it basically leverages the idea of the binary search. left node is smaller node then

If the node that is to be deleted is the leaf node then we can simply delete it.
Concept of the inorder succesor and inorder predecessor is used when we want to delete a particular node from a binary search tree. This will be used when there are two children of a particular node.

The same nodes if are inserted in some other order will generate a different height while in the other case it will geenrate the different height.

In case of the self balancing binary search trees the order of the insertion of the elements matter. If the elements are inserted in wrong order in the binary search tree then we can simply say that the binary search tree can be skewed. The balanced binary search tree maintains the height of the binary search tree to almost log n.

The extra task of the restructuring of the tree is done while inserting and deletion of the elements.

In case of the avl tree we consider the left height and the right subtree height of each internal node if the absolute difference between those is >1 then we say that the binary search tree is not balanced.

There are four type of the anomaly which can occur 
1) Left Left.
2) Right Right
3) Left Right
4) Right Left

In case of the left left or right right anomaly we rotate the tree using the center node to anticlockwise or clockwise direction respectively.
In case of the left right anomaly and the right left anomaly the anomaly is converted to left left or right right.

In case of avl trees there are many rotations while in case of the red black tree there are very less rotations and therefore the red black trees are used more than the avl trees.

The pointers which red black tree obeys.
1) Every node is either red or black.
2) Root is always black.
3) No two consecutive nodes are red.
4) Number of black nodes from every node to all of the descendent leaves should be same.

There is one property of the red black tree which we can encounter using this particular technique the height to the closest leaf can be at max half of the farthest leaf.

Application of the binary search tree are as follows.
1) To maintain sorted stream of data.
2) Doubly ended priority queue.
3) To solve the problem.

Set in C++ are used to store the data in sorted order the underlying data structure for the set is red black tree.

The syntax for creating the set data structure is as fllows.
set<int> s;
The other way for its creation is set<int,greater<int>> s;
The set which is provided to us also has the iterators in place as well. we have the begin and the end iterator for those.

While the creation of the heap data structure there are two types of heap. 
1) Min Heap -> In case of min heap the parent node is always smaller than its children
2) Max Heap -> In case of max heap the parent node is always greater than its children

Heaps are always complete binary trees(Means that the filling of the trees is always from left to right.)

There are many advantages of heap data structure

here we need to find the maximum number of items that we can take such that the sum is also positive.
This can be done in two ways one solution is using the sorting approach in which we sort the entire array and then we take the initial items until the sum is a +ve number

The other approach that we follow is more efficient approach in that we create a heap.

In case of the kosaraju algorithm we need to find the strongly connected components that are possible in a particular graph.

A particular set of vertices can be considered as strongly connected if each vertex in that set we can visit other vertex.

Articulation Point in a graph is said to be the vertex whose removal will make the particular graph disconnected.

In case of the undirected graph the conencted components are very easy to find.

Each of the case we will be starting the traversal from sink vertex.

we can easily find the articulation points using the approach that if a node in dfs tree is non root and if its any children has a back edge then we can say so it works.
leaf is never an articulation point.

low time is the lowest discovery time which is reachable from current node is.

All the types of questions which are optimization based can be solved using the greedy approach. we need to find the min number of coins we will be using sorting as our basic approach.

The main thing is that we want to maximize the profit that is present.
every job takes 1 unit of time.
THe job with the most profit is kept farthest.

Huffman coding is a popular apprach of encoding and decoding data in lossless way. Lossless means if that we have encoded the data then we will be able to decompress data without losing it.
In the file itself there can be as many characters as possible.

huffman coding is the variable length coding different characters will be having different lengths and while sending those that can be checked.

We basically follow the greedy approach in which the character with most occurence takes least number of bit. For each and every character we will associate a freq and then we will be using heap.
Huffman algorithm creates a prefix free code which means that similar prefix can be used to represent different characters.

every left node is represent as 0 and right as 1. binary tree created is a full binary tree.
Dynamic Programming is basically some modification on plain recursion. This optimization makes the time complexity very less.
All the problems can be solved using dynamic programming but cannot say whether that can be done in polynomial time.

There are many repetition which should not be computed over and over again therefore it is saved.

This particular approach is used a lot in case of the programming languages in case of implementing the diff utility this is usually used for finding the difference in the code before and now is found using this particular utility.

What ever is extra is first is removed and the part extra in second has been added to the file.

Edit distance problem is used for the creation of dictionary as per our requriement.

There are different variations of the lis problem which are used a lot. Like how many items we need to delete in order to make it sorted.

There are many different variations of the Longest increasing subsequence which are used a lot.

In case of the longest increasing subsequence we have the subsequence using the increasing term.
Min deletions to make an array sorted can be done using the concept of longest increasing subsequence.

one more version to this lis problem is that we are provided with a pair in which a>b (a,b) (c,d) we need to find the c,d in such a way that a<b<c<d

In the matrix chain multiplication we are thinking of finding the integer multiplication which are required in order to multiply two matrices we will be choosing the one which will take least time.

In case of the naive approach for the palindromic partitioning
In the base case we write if the string is palindrome then we will be simply returning the value as it is. (All possible places we need to find the partitions.) We add 1 to the result.

if(isPalindrome(s,i,j)){
if the particular string is already palindrome then we actually don't have to do anything.
    return 0;
}
int res  = INT_MAX; here we already know that the result is not palindrome.

for(int k=i;k<j;k++){
    res = min(res,1+pal(s,i,k)+pal(s,k+1,j));
}
return res;

There are many overlapping subproblems therefore we can use dynamic programming in this particular case.
we will be filling the arrays diagonal by diagonal

Tries are basically used as the dictionaries as per our requirement. (These are basically used for the efficient way for searching a particular value as per our requirement.)
search of the strings in trie is a lot easier.

In case of the dynamic programming there are three types of problems. It is basically at which all locations we can perform cuts.

The steps are simple.

    Check if root is NULL. return if yes
    // Visited hashmap is needed to prevent cycles. Example, consider a undirected rectangle shape graph from A->B->C->D->A. If we dont' keep visited, it will keep on going.
    If no, clone the node and add the entry pair to hashmap as visited[node] = clonedNode;
    Iterate over neighbours and do dfs for each. While we are looping over this neighbour list, we can also fill neighbours of cloned node with the result from recursive calls.
    Return clonedNode at each recursive call

DFS Solution

class Solution {
private:
    unordered_map<Node*, Node*> visited;
public:
    Node* cloneGraph(Node* node) {
        if(node == NULL)
            return node;
        if(visited[node])
            return visited[node];
        
        Node* cloned = new Node(node->val);
        visited[node] = cloned;
        
        for(auto nei: node->neighbors){
            cloned->neighbors.push_back(cloneGraph(nei));
        }
        return cloned;
        
    }
};

Steps for BFS are almost same. Most of the things are relatable if you have studied trees level order traversal.

So instead of the stack here, we use queue to process the nodes and their neighbours.
variable curr serves as the present root. We iterate over its children in the same way.
Inside the neigbour loop, if the neighbour is not visited, we do two things

    Clone the neighbour and Put the entry of <neighbour, clonedNeighbour> into visited hashmap.
    push the neighbour into queue. This is to process the children of the neighbours children in future iterations over queue.

We fill the neigbours vector/list in the same way.
BFS Solution

Node* cloneGraph(Node* node){
        if(node == NULL)
            return node;
        unordered_map<Node*, Node*> visited;
        queue<Node*> Q;
        Q.push(node);
        visited[node] = new Node(node->val);
        while(!Q.empty()){
            int n = Q.size();
            Node* curr = Q.front();
            Q.pop();
            for(auto nei: curr->neighbors){
                if(!visited[nei]){
                     visited[nei] = new Node(nei->val);
                     Q.push(nei);
                }
                visited[curr]->neighbors.push_back(visited[nei]);
            }
        }
        return visited[node];

    }

we want to rearrange the characters in such a way that no two characters are adjacent.
if we want to find median of a particular stream which is provided to us then we will have to consider two seperate heaps one is the min heap and the other one is the max heap.